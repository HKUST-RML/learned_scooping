{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Construct customized ResNet\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, pcpt_block, pcpt_layers, scoop_block, scoop_layers, h, w, pcpt_is_upsample=0, scoop_is_upsample=0):\n",
    "        self.inplanes = 64\n",
    "        self.pcpt_is_upsample = pcpt_is_upsample\n",
    "        super(ResNet, self).__init__()\n",
    "        self.pcpt_conv1 = nn.Conv2d(4, 64, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.pcpt_bn1 = nn.BatchNorm2d(64)\n",
    "        self.pcpt_relu = nn.ReLU(inplace=True)\n",
    "        self.pcpt_maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.pcpt_upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.pcpt_layer1 = self._make_layer(pcpt_block, 128, pcpt_layers[0])\n",
    "        self.pcpt_layer2 = self._make_layer(pcpt_block, 256, pcpt_layers[1])\n",
    "        self.pcpt_layer3 = self._make_layer(pcpt_block, 512, pcpt_layers[2])\n",
    "\n",
    "        self.inplanes = 512\n",
    "        self.scoop_is_upsample = scoop_is_upsample\n",
    "        self.scoop_upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.scoop_layer1 = self._make_layer(scoop_block, 256, scoop_layers[0])\n",
    "        self.scoop_layer2 = self._make_layer(scoop_block, 128, scoop_layers[1])\n",
    "        self.scoop_layer3 = self._make_layer(scoop_block, 64, scoop_layers[2])\n",
    "        self.scoop_conv1 = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.scoop_bn1 = nn.BatchNorm2d(1)\n",
    "        self.scoop_conv2 = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.scoop_bn2 = nn.BatchNorm2d(3)\n",
    "        self.scoop_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.scoop_head = nn.Linear(h*w, 1)\n",
    "\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pcpt_conv1(x)\n",
    "        x = self.pcpt_bn1(x)\n",
    "        x = self.pcpt_relu(x)\n",
    "        x = self.pcpt_maxpool(x)\n",
    "\n",
    "        x = self.pcpt_layer1(x)\n",
    "        x = self.pcpt_maxpool(x)\n",
    "        x = self.pcpt_layer2(x)\n",
    "        x = self.pcpt_layer3(x)\n",
    "\n",
    "        x = self.scoop_layer1(x)\n",
    "        x = self.scoop_layer2(x)\n",
    "        x = self.scoop_upsample(x)\n",
    "        x = self.scoop_layer3(x)\n",
    "        x = self.scoop_upsample(x)\n",
    "\n",
    "        x = self.scoop_conv2(x)\n",
    "        x = self.scoop_bn2(x)\n",
    "        x = self.scoop_relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "import scipy.ndimage\n",
    "BATCH_SIZE =  32\n",
    "NUM_EPOCH = 50\n",
    "\n",
    "# make data\n",
    "\n",
    "data_input = np.load(\"data_20210715/input_data_array_20210715.npy\")/255.0\n",
    "#normalization=np.ones(data_input.shape)\n",
    "#normalization[:,:,:]=[255,255,255,0.08]\n",
    "#data_input = data_input/normalization\n",
    "#print(data_input)\n",
    "print(data_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "'''\n",
    "input_array_mean = np.mean(np.mean(np.mean(data_input, axis=0), axis=0), axis=0)\n",
    "input_array_std = np.mean(np.mean(np.std(data_input, axis=0), axis=0), axis=0)\n",
    "print('input_array_mean', input_array_mean)\n",
    "print('input_array_std', input_array_std)\n",
    "'''\n",
    "\n",
    "#input_array_mean=np.ones(data_input.shape)\n",
    "#input_array_mean[:,:,:]=[0.54569177,0.48216905,0.49853667,0.42829879]\n",
    "#input_array_std=np.ones(data_input.shape)\n",
    "#input_array_std[:,:,:]=[0.31950833,0.29141234,0.30389949,0.20277719]\n",
    "\n",
    "#data_input = (data_input-input_array_mean)/input_array_std\n",
    "\n",
    "temp_index_set = random.sample(range(len(data_input)), 50)\n",
    "#print(temp_index_set)\n",
    "\n",
    "temp_index_set_other = list(set(range(len(data_input))).difference(set(temp_index_set)))\n",
    "#print(temp_index_set_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "data_input = torch.from_numpy(data_input).permute(0,3,1,2)\n",
    "\n",
    "train_data_input = data_input[temp_index_set_other, :, :, :]\n",
    "val_data_input = data_input[temp_index_set, :, :, :]\n",
    "htmap_h = data_input.shape[2]\n",
    "htmap_w = data_input.shape[3]\n",
    "del data_input\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "data_label = np.load(\"data_20210715/label_data_array_20210715.npy\")\n",
    "print(data_label.shape)\n",
    "data_label[data_label==0]=2\n",
    "data_label[data_label==255]=0\n",
    "data_label[(data_label==128)]=1\n",
    "#print(data_label[np.logical_and(np.logical_and((data_label!=0),(data_label!=1)),(data_label!=2))])\n",
    "\n",
    "\n",
    "good_cnt = (data_label==1).sum()\n",
    "bad_cnt = (data_label==2).sum()\n",
    "print(good_cnt, bad_cnt)\n",
    "total = good_cnt + bad_cnt\n",
    "\n",
    "weights = [0, total/good_cnt, total/bad_cnt]\n",
    "class_weights = torch.FloatTensor(weights)\n",
    "if torch.cuda.is_available():\n",
    "    class_weights = class_weights.cuda()\n",
    "print('Class weights:', class_weights)\n",
    "\n",
    "train_data_label = data_label[temp_index_set_other, :, :]\n",
    "val_data_label = data_label[temp_index_set, :, :]\n",
    "del data_label\n",
    "gc.collect()\n",
    "print(train_data_label.shape, train_data_label.dtype)\n",
    "print(val_data_label.shape, val_data_label.dtype)\n",
    "train_data_label = torch.from_numpy(train_data_label)\n",
    "val_data_label = torch.from_numpy(val_data_label)\n",
    "\n",
    "train_data_label = train_data_label.long()\n",
    "val_data_label = val_data_label.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_torch_dataset = Data.TensorDataset(train_data_input, train_data_label)\n",
    "loader = Data.DataLoader(dataset=train_torch_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet(pcpt_block=BasicBlock, pcpt_layers=[1,5,1], scoop_block=BasicBlock, scoop_layers=[1,5,1], h=htmap_h, w=htmap_w).cuda()     # define the network\n",
    "print(net)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(params = net.parameters(), lr=1e-4, momentum=0.9, weight_decay=2e-5)\n",
    "optimizer = torch.optim.Adam(params = net.parameters(), lr=1e-4)\n",
    "#optimizer = torch.optim.SGD(params = net.parameters(), lr=1e-4)\n",
    "loss_func = torch.nn.CrossEntropyLoss(weight=class_weights).cuda()  # the target label is NOT an one-hotted\n",
    "\n",
    "val_data_input = val_data_input.cuda().float()\n",
    "val_data_label = val_data_label.cuda()\n",
    "\n",
    "min_val_loss_print=float('inf')\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for step, (batch_data, batch_label) in enumerate(loader):\n",
    "        batch_data = batch_data.cuda().float()\n",
    "        batch_label = batch_label.cuda()\n",
    "        net.train()\n",
    "        output  = net(batch_data)\n",
    "        train_loss = loss_func(output,batch_label)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(net.parameters(), max_norm=20, norm_type=2)\n",
    "        optimizer.step()\n",
    "        train_loss_print = train_loss.data.item()\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            val_output  = net(val_data_input)\n",
    "            val_loss = loss_func(val_output,val_data_label)\n",
    "            val_loss_print = val_loss.data.item()\n",
    "            torch.cuda.empty_cache()\n",
    "        #print('epoch: ', epoch, '  step: ', step, '  train loss: ', train_loss_print, ' val loss: ', val_loss_print)\n",
    "        print('epoch: ', epoch, '  step: ', step, '  train loss: ', train_loss_print, ' val loss: ', val_loss_print)\n",
    "        if val_loss_print < min_val_loss_print:\n",
    "            torch.save(net.state_dict(), 'net_params_20210715/net_params_20210715_1/epoch_'+str(epoch)+'.pkl') \n",
    "            min_val_loss_print = val_loss_print\n",
    "            print('min_val_loss_print', min_val_loss_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "a=torch.from_numpy((np.random.rand(22074, 200, 200)*200).astype(np.uint8))\n",
    "print(a)\n",
    "np.array([1]).astype(np.uint8)\n",
    "print(np.array([1]).astype(np.uint8).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
